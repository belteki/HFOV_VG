{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](./pageheader_rose2_babies.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing HFOV-VG data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Author: Dr Gusztav Belteki**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "This Notebook imports the pickle archive produced by **HFOV_all.ipynb**: *slow_measurements_hfov*. It then selects the recordings only which contain at least 12 hours of HFOV-VG ventilation. After some preprocessing (adding VThf and Pmax data) it export them as a pickle archive: *slow_measurements_hfov_vg*, *slow_measurements_hfov_no_vg*, *vent_settings_selected_hfov_vg*, *vent_settings_selected_hfov_no_vg*, *clinical_details_hfov_vg*.\n",
    "\n",
    "Processing steps:\n",
    "* Keep only recordings which have HFOV-VG mode\n",
    "* Remove recordings which are < 12 hours long\n",
    "* Keep only one recording per patient\n",
    "* Separate periods of VG and no VG in the recordings which have both\n",
    "* Remove DG062 as its VG component is only a couple minutes\n",
    "* Calculate Vthf / dP ratio and add it to the DataFrames\n",
    "* Limit ventilator settings to the VG or noVG periods\n",
    "* Retrieve relevant ventilator settings normalize to body weight and add them to HFOV data\n",
    "* Calculate difference between the set and actual VThf in case of VG\n",
    "* Calculate difference between the set and actual and amplitude\n",
    "* Limit clinical details to the selected HFOV-VG recordingsÂ¶\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the necessary libraries and setting options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn as sk\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import pickle\n",
    "\n",
    "from scipy import stats\n",
    "from pandas import Series, DataFrame\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "matplotlib.style.use('classic')\n",
    "matplotlib.rcParams['figure.facecolor'] = 'w'\n",
    "\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Python version: {}\".format(sys.version))\n",
    "print(\"pandas version: {}\".format(pd.__version__))\n",
    "print(\"matplotlib version: {}\".format(matplotlib.__version__))\n",
    "print(\"NumPy version: {}\".format(np.__version__))\n",
    "print(\"SciPy version: {}\".format(sp.__version__))\n",
    "print(\"IPython version: {}\".format(IPython.__version__))\n",
    "print(\"scikit-learn version: {}\".format(sk.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import custom functions from own module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gb_loader import *\n",
    "from gb_stats import *\n",
    "from gb_transform import *\n",
    "from gb_visualizer import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List and set the working directory and the directory to write out data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Topic of the Notebook which will also be the name of the subfolder containing results\n",
    "TOPIC = 'HFOV_VG'\n",
    "\n",
    "# Name of the external hard drive\n",
    "DRIVE = 'GUSZTI'\n",
    "\n",
    "# Directory containing clinical and blood gas data\n",
    "CWD = '/Users/guszti/ventilation_draeger'\n",
    "\n",
    "# Directory on external drive to read the ventilation data from\n",
    "DIR_READ = '/Volumes/%s/ventilation_data' % DRIVE\n",
    "\n",
    "# Directory on external drive to read in dump large datasets\n",
    "DIR_READ_2 = '/Volumes/%s/data_dump/draeger/%s' % (DRIVE, 'HFOV_all')\n",
    "\n",
    "# Directory to write results and selected images to \n",
    "if not os.path.isdir('%s/%s/%s' % (CWD, 'Analyses', TOPIC)):\n",
    "    os.makedirs('%s/%s/%s' % (CWD, 'Analyses', TOPIC))\n",
    "DIR_WRITE = '%s/%s/%s' % (CWD, 'Analyses', TOPIC)\n",
    "\n",
    "# Images and raw data will be written on an external hard drive\n",
    "if not os.path.isdir('/Volumes/%s/data_dump/draeger/%s' % (DRIVE, TOPIC)):\n",
    "    os.makedirs('/Volumes/%s/data_dump/draeger/%s' % (DRIVE, TOPIC))\n",
    "DATA_DUMP = '/Volumes/%s/data_dump/draeger/%s' % (DRIVE, TOPIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(CWD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR_READ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR_READ_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR_WRITE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DUMP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import processed HFOV data from pickle archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('%s/%s.pickle' % (DIR_READ_2, 'slow_measurements_hfov_1'), 'rb') as handle:\n",
    "    slow_measurements_1 = pickle.load(handle)\n",
    "    \n",
    "with open('%s/%s.pickle' % (DIR_READ_2, 'slow_measurements_hfov_2'), 'rb') as handle:\n",
    "    slow_measurements_2 = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slow_measurements = {**slow_measurements_1, **slow_measurements_2}\n",
    "del slow_measurements_1; del slow_measurements_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('%s/%s.pickle' % (DIR_READ_2, 'vent_settings_selected_hfov'), 'rb') as handle:\n",
    "    vent_settings_selected = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('%s/%s.pickle' % (DIR_READ_2, 'clinical_details_hfov'), 'rb') as handle:\n",
    "    clinical_details = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# List of recordings\n",
    "\n",
    "recordings = sorted(slow_measurements.keys())\n",
    "print(recordings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(slow_measurements)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keep only recordings which have HFOV-VG mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify recordings which have HFOV mode and collect their name in a list\n",
    "# Print those ones which do not have PC_AC periods\n",
    "\n",
    "recordings = [recording for recording in recordings if\n",
    "             'Ampl hf max' in  vent_settings_selected[recording]['Name'].values]\n",
    "\n",
    "for recording in sorted(slow_measurements.keys()):\n",
    "    if recording not in recordings:\n",
    "        slow_measurements.pop(recording)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(recordings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(recordings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove recordings which are < 12 hours long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for recording in recordings:\n",
    "    if len(slow_measurements[recording]) < 12 * 3600:\n",
    "        slow_measurements.pop(recording)\n",
    "\n",
    "recordings = sorted(slow_measurements.keys())\n",
    "print(recordings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(recordings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keep only one recording per patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "to_remove = ['DG005_3', 'DG038_2', 'DG040_2']\n",
    "\n",
    "for recording in to_remove:\n",
    "    slow_measurements.pop(recording)\n",
    "\n",
    "recordings = sorted(slow_measurements.keys())\n",
    "print(recordings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(recordings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which of the recordings containg also periods without volume guarantee? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recordings_with_no_vg = [recording for recording in recordings \n",
    "                        if 'Ampl hf' in vent_settings_selected[recording]['Id'].unique()]\n",
    "\n",
    "print(recordings_with_no_vg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keep only HFOV-VG periods\n",
    "\n",
    "This is better done by manual inspection of files than by writing a complicated script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slow_measurements['DG005_1'] = slow_measurements['DG005_1']['2015-10-13 14:48:34':'2015-10-14 19:57:07'].copy()\n",
    "slow_measurements['DG018_1'] = slow_measurements['DG018_1']['2015-12-13 01:22:29':].copy()\n",
    "slow_measurements['DG032_2'] = slow_measurements['DG032_2'][:'2016-03-24 00:57:00'].copy()\n",
    "slow_measurements['DG038_1'] = slow_measurements['DG038_1']['2016-05-06 20:31:56':'2016-05-11 11:21:15'].copy()\n",
    "slow_measurements['DG040_1'] = slow_measurements['DG040_1']['2016-06-09 17:12:57':'2016-06-11 17:45:14'].copy()\n",
    "slow_measurements['DG049'] = slow_measurements['DG049']['2016-09-02 08:19:34':].copy()\n",
    "slow_measurements['DG050'] = slow_measurements['DG050']['2016-09-06 00:23:02':].copy()\n",
    "slow_measurements['DG053'] = slow_measurements['DG053']['2016-10-15 10:32:44':].copy()\n",
    "slow_measurements['DG062'] = slow_measurements['DG062']['2017-07-21 18:41:57': '2017-07-21 18:49:14'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recording duration of the HFOV-VG recordings\n",
    "\n",
    "recording_times =[(recording, round((len(slow_measurements[recording]) / 3600), 2)) for recording in recordings]\n",
    "recording_times = DataFrame(recording_times, columns = ['recording', 'duration (hours)'])\n",
    "recording_times.set_index('recording', inplace = True)\n",
    "recording_times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove DG062 as its VG component is only a couple minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del slow_measurements['DG062']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recordings = sorted(slow_measurements.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sorted(slow_measurements.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(slow_measurements)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate duration and length of the final HFOV-VG recordings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_periods = {}\n",
    "for recording in recordings:\n",
    "    start = str(slow_measurements[recording].index[0])\n",
    "    end = str(slow_measurements[recording].index[-1])\n",
    "    recording_periods[recording] = [start, end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_duration_frame = DataFrame(recording_periods, index = ['start', 'end'])\n",
    "recording_duration_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_times_VG =[(recording, round((len(slow_measurements[recording]) / 3600), 2)) \n",
    "                     for recording in recordings]\n",
    "recording_times_VG = DataFrame(recording_times_VG, columns = ['recording', 'duration (hours)'])\n",
    "recording_times_VG.set_index('recording', inplace = True)\n",
    "recording_times_VG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_time_total_VG = 0\n",
    "\n",
    "for recording in recordings:\n",
    "    recording_time_total_VG += len(slow_measurements[recording])\n",
    "print('Total recording time is %d seconds' % recording_time_total_VG)\n",
    "print('Total recording time is %d hours' % (recording_time_total_VG / 3600))\n",
    "print('Total recording time is %.2f days' % (recording_time_total_VG / 86400))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine slow_measurement DataFrames into one "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = []\n",
    "for recording in recordings:\n",
    "    total.append(slow_measurements[recording])\n",
    "slow_measurements_all = pd.concat(total)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(slow_measurements_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many days of recording in total?\n",
    "\n",
    "len(slow_measurements_all) / 3600 /24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slow_measurements_all.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slow_measurements_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many percent of points are missing for the different parameters?\n",
    "missing = slow_measurements_all.isnull().sum()\n",
    "missing_pc = round((missing / len(slow_measurements_all)) * 100, 3)\n",
    "missing_pc.sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is very low percentage. There is no need to remove any parameter (column). Instead, remove the rows with missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = len(slow_measurements_all)\n",
    "print('Before removal: %d rows' % a)\n",
    "\n",
    "for recording in recordings:\n",
    "    slow_measurements[recording].dropna(axis = 0, how = 'any', inplace = True)\n",
    "    \n",
    "total = []\n",
    "for recording in recordings:\n",
    "    total.append(slow_measurements[recording])\n",
    "slow_measurements_all = pd.concat(total)\n",
    "\n",
    "b = len(slow_measurements_all)\n",
    "print('After removal: %d rows' % b)\n",
    "print('Removed %d rows' % (a-b))\n",
    "print('Removed %.2f percent of the data' % (100 * (a-b) / a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limit ventilator settings to the recordings containing HFOV-VG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit to recordings containing HFOV-VG\n",
    "\n",
    "vent_settings_selected = {key : value  for key, value in vent_settings_selected.items() if\n",
    "                          key in recordings}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve relevant ventilator settings and add them to HFOV data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**dPmax**, and **VThf**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame with changes in Ampl max (dP_max) and reindex it according it to slow_measurements data\n",
    "\n",
    "dP_set_VG = {}\n",
    "for recording in recordings:\n",
    "    dP_set_VG[recording] = \\\n",
    "        vent_settings_selected[recording][vent_settings_selected[recording].Id == 'Ampl hf max'].copy()\n",
    "    dP_set_VG[recording]['dPmax_set'] = dP_set_VG[recording]['Value New']\n",
    "    dP_set_VG[recording] = dP_set_VG[recording][['Date_Time', 'dPmax_set']]\n",
    "    # reindex the Dataframe with the index of slow_measurements will allow concatenation\n",
    "    # with the settings data filled in for all rows of the slow_measurements DataFrame\n",
    "    dP_set_VG[recording] = dP_set_VG[recording].reindex(slow_measurements[recording].index, method = 'ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame with changes in VThf and reindex it according it to slow_measurements data\n",
    "\n",
    "VThf_set = {}\n",
    "for recording in recordings:\n",
    "    VThf_set[recording] = \\\n",
    "        vent_settings_selected[recording][vent_settings_selected[recording].Id == 'VThf'].copy()\n",
    "    VThf_set[recording]['VThf_set'] = VThf_set[recording]['Value New']\n",
    "    VThf_set[recording] = VThf_set[recording][['Date_Time', 'VThf_set']]\n",
    "    VThf_set[recording] = VThf_set[recording].reindex(slow_measurements[recording].index, method = 'ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_values = {}\n",
    "for recording in recordings:\n",
    "    set_values[recording] = pd.concat([dP_set_VG[recording]['dPmax_set'], VThf_set[recording]['VThf_set']], \n",
    "                                       join = 'inner', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for recording in recordings:\n",
    "    slow_measurements[recording] = pd.concat([slow_measurements[recording], set_values[recording]],\n",
    "                                            join = 'inner', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create additional features by normalizing parameters to the body weight or the square of the body weight and also calculate VThf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add weight-normalized parameters to the 1/sec data\n",
    "\n",
    "for recording in recordings:  \n",
    "        \n",
    "    # These columns normalize VThf, MV, MVi, MVe, MVleak to the body weight\n",
    "    slow_measurements[recording]['VThf_kg'] = \\\n",
    "         slow_measurements[recording]['VThf']  / slow_measurements[recording]['weight']\n",
    "    slow_measurements[recording]['VThf_set_kg'] = \\\n",
    "         slow_measurements[recording]['VThf_set']  / slow_measurements[recording]['weight']\n",
    "    slow_measurements[recording]['MV_kg'] = \\\n",
    "         slow_measurements[recording]['MV']  / slow_measurements[recording]['weight']\n",
    "    slow_measurements[recording]['MVi_kg'] = \\\n",
    "         slow_measurements[recording]['MVi']  / slow_measurements[recording]['weight']\n",
    "    slow_measurements[recording]['MVe_kg'] = \\\n",
    "         slow_measurements[recording]['MVe']  / slow_measurements[recording]['weight']\n",
    "    slow_measurements[recording]['MVleak_kg'] = \\\n",
    "         slow_measurements[recording]['MVleak']  / slow_measurements[recording]['weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the weight square-normalized DCO2\n",
    "\n",
    "for recording in recordings:  \n",
    "        \n",
    "    slow_measurements[recording]['DCO2_kg2'] = \\\n",
    "         slow_measurements[recording]['DCO2']  / (slow_measurements[recording]['weight'] ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate difference between the set and actual VThf in case of VG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for recording in recordings:\n",
    "    slow_measurements[recording]['VThf_diff_kg'] = abs(slow_measurements[recording]['VThf_set_kg'] - \\\n",
    "        slow_measurements[recording]['VThf_kg'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate difference between the set and actual and amplitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for recording in recordings:\n",
    "    slow_measurements[recording]['dP_diff'] = abs(slow_measurements[recording]['dPmax_set'] - \\\n",
    "        slow_measurements[recording]['amplitude'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check distribution of VThf data in detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qcats_VThf_kg = pd.qcut(slow_measurements_all.VThf_kg, q = 10,)\n",
    "qcats_VThf_kg.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = list(range(0, 22, 2)) + [500]\n",
    "cats_VThf_kg = pd.cut(slow_measurements_all.VThf_kg, bins, right = False)\n",
    "cats_VThf_kg.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove rows with VThf > 6 mL/kg \n",
    "\n",
    "These are clearly outliers probably reflecting an open ventilator circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = len(slow_measurements_all)\n",
    "print('Before removal: %d rows' % a)\n",
    "\n",
    "for recording in recordings:\n",
    "    slow_measurements[recording] = slow_measurements[recording][slow_measurements[recording]['VThf_kg'] <= 6]\n",
    "    \n",
    "total = []\n",
    "for recording in recordings:\n",
    "    total.append(slow_measurements[recording])\n",
    "slow_measurements_all = pd.concat(total)   \n",
    "\n",
    "b = len(slow_measurements_all)\n",
    "print('After removal: %d rows' % b)\n",
    "print('Removed %d rows' % (a-b))\n",
    "print('Removed %.2f percent of rows' % ((a-b) / a * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  How many rows from which recording?\n",
    "\n",
    "recs = slow_measurements_all.groupby('recording')\n",
    "recs.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limit clinical details to the selected HFOV-VG recordings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clinical_details = clinical_details.loc[recordings]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export processed data to to pickle archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('%s/%s.pickle' % (DATA_DUMP, 'slow_measurements_hfov_vg'), 'wb') as handle:\n",
    "    pickle.dump(slow_measurements, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('%s/%s.pickle' % (DATA_DUMP, 'vent_settings_selected_hfov_vg'), 'wb') as handle:\n",
    "    pickle.dump(vent_settings_selected, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('%s/%s.pickle' % (DATA_DUMP, 'clinical_details_hfov_vg'), 'wb') as handle:\n",
    "    pickle.dump(clinical_details, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Export ventilation settings, clinical details and recording durations as Excel files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter('%s/%s' % (DIR_WRITE, 'ventilator_settings_selected.xlsx'))\n",
    "for recording in recordings:\n",
    "    vent_settings_selected[recording].to_excel(writer,'%s' % recording)\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter('%s/%s' % (DIR_WRITE, 'clinical_details.xlsx'))\n",
    "clinical_details.to_excel(writer,'clinical_details')\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter('%s/%s' % (DIR_WRITE, 'recording_periods.xlsx'))\n",
    "recording_duration_frame.T.to_excel(writer,'rec_periods.xlsx')\n",
    "writer.save()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
