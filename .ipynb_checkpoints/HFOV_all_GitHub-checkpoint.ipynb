{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](./pageheader_rose2_babies.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing HFOV data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Author: Dr Gusztav Belteki\n",
    "\n",
    "Contact: gbelteki@aol.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook considers all the recordings from **both ventilator service evaluations** but only keeps the data which contain HFOV ventilation. It performs preprocessing (e.g. resampling to 1 second periods, normalising relevant parameters to birth weight, removing irrelevant parameters, adding some ventilator settings). It then exports data a pickle archive: *slow_measurements_hfov_1*, *slow_measurements_hfov_2*, *vent_settings_selected_hfov*, *clinical_details_hfov*.\n",
    "\n",
    "Data processing performed in this notebook:\n",
    "\n",
    "* Resample data to 1/sec to remove half-empty rows\n",
    "* Remove non-HFOV periods\n",
    "* Normalise relevant parameters to the body weight\n",
    "* Correct the problem with Phf column names\n",
    "* Retrieve the set frequency (Hz) and adding it to the DataFrames\n",
    "* Add the recording's name to the DataFrames as a categorical variable\n",
    "* Limit ventilation settings to the duration of the HFOV recordings\n",
    "* Limit clinical details to the hfov recordings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the necessary libraries and setting options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn as sk\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import pickle\n",
    "\n",
    "from scipy import stats\n",
    "from pandas import Series, DataFrame\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "matplotlib.style.use('classic')\n",
    "matplotlib.rcParams['figure.facecolor'] = 'w'\n",
    "\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Python version: {}\".format(sys.version))\n",
    "print(\"pandas version: {}\".format(pd.__version__))\n",
    "print(\"matplotlib version: {}\".format(matplotlib.__version__))\n",
    "print(\"NumPy version: {}\".format(np.__version__))\n",
    "print(\"SciPy version: {}\".format(sp.__version__))\n",
    "print(\"IPython version: {}\".format(IPython.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import custom functions from own module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gb_loader import *\n",
    "from gb_stats import *\n",
    "from gb_transform import *\n",
    "from gb_visualizer import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List and set the working directory and the directory to write out data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Topic of the Notebook which will also be the name of the subfolder containing results\n",
    "TOPIC = 'HFOV_all'\n",
    "\n",
    "# Name of the external hard drive\n",
    "DRIVE = 'GUSZTI'\n",
    "\n",
    "# Directory containing clinical and blood gas data\n",
    "CWD = '/Users/guszti/ventilation_draeger'\n",
    "\n",
    "# Directory on external drive to read the ventilation data from\n",
    "DIR_READ_1 = '/Volumes/%s/Draeger/service_evaluation_old' % DRIVE\n",
    "DIR_READ_2 = '/Volumes/%s/Draeger/service_evaluation_new' % DRIVE\n",
    "\n",
    "# Directory to write results and selected images to \n",
    "if not os.path.isdir('%s/%s/%s' % (CWD, 'Analyses', TOPIC)):\n",
    "    os.makedirs('%s/%s/%s' % (CWD, 'Analyses', TOPIC))\n",
    "DIR_WRITE = '%s/%s/%s' % (CWD, 'Analyses', TOPIC)\n",
    "\n",
    "# Images and raw data will be written on an external hard drive\n",
    "if not os.path.isdir('/Volumes/%s/data_dump/draeger/%s' % (DRIVE, TOPIC)):\n",
    "    os.makedirs('/Volumes/%s/data_dump/draeger/%s' % (DRIVE, TOPIC))\n",
    "DATA_DUMP = '/Volumes/%s/data_dump/draeger/%s' % (DRIVE, TOPIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(CWD)\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR_WRITE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DUMP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List of the  recordings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a list of all recordings\n",
    "\n",
    "recordings_1 = ['DG001', 'DG002_1', 'DG002_2', 'DG003', 'DG004', 'DG005_1', 'DG005_2', 'DG005_3', \n",
    "              'DG006_1', 'DG006_2', 'DG006_3', 'DG007', 'DG008', 'DG009', 'DG010', 'DG011', \n",
    "              'DG012', 'DG013', 'DG014', 'DG015', 'DG016', 'DG017', 'DG018_1', 'DG018_2', 'DG019',\n",
    "              'DG020', 'DG021', 'DG022', 'DG023', 'DG024',  'DG025', 'DG026', 'DG027', 'DG028', \n",
    "              'DG029', 'DG030', 'DG031', 'DG032_1', 'DG032_2', 'DG033', 'DG034', 'DG035', 'DG036', \n",
    "              'DG037', 'DG038_1', 'DG038_2', 'DG039', 'DG040_1', 'DG040_2', 'DG041', 'DG042', \n",
    "              'DG043', 'DG044', 'DG045', 'DG046_1', 'DG046_2', 'DG047', 'DG048', 'DG049', 'DG050',\n",
    "              'DG051_1', 'DG051_2', 'DG052', 'DG053', 'DG054', 'DG055', 'DG056', 'DG057', 'DG058',\n",
    "              'DG059', 'DG060']\n",
    "\n",
    "recordings_2 = ['DG061', 'DG062', 'DG063', 'DG064', 'DG065', 'DG066', 'DG067_1', 'DG067_2', 'DG068', \n",
    "                'DG069_1', 'DG069_2', 'DG070', 'DG071', 'DG072', 'DG073', 'DG074', 'DG075', 'DG076',\n",
    "                'DG077', 'DG078', 'DG079', 'DG080', 'DG081', 'DG082', 'DG083', 'DG084', 'DG085',\n",
    "                'DG086', 'DG087', 'DG088', 'DG089', 'DG090']\n",
    "\n",
    "recordings = recordings_1 + recordings_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(recordings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import clinical details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clinical details of the both service evaluation\n",
    "clinical_details = pd.read_excel('%s/data_grabber_patient_data_combined_all.xlsx' % CWD)\n",
    "clinical_details.index = clinical_details['Recording']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Limit to the recordings listed\n",
    "clinical_details = clinical_details.loc[recordings]\n",
    "clinical_details;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clinical_details['Recording start'] = pd.to_datetime(clinical_details['Recording period'].apply(lambda x: x[:10]),\n",
    "                dayfirst = True)\n",
    "clinical_details['Postnatal age'] = clinical_details['Recording start'] - clinical_details['Date of birth']\n",
    "clinical_details['Corrected gestation'] = clinical_details['Gestation'] + \\\n",
    "                clinical_details['Postnatal age'].astype(int) / (1E+9 * 3600 * 24 * 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "clinical_details.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_weights = {}\n",
    "for recording in recordings:\n",
    "    current_weights[recording] = clinical_details.loc[recording, 'Current weight' ] / 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import ventilator modes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vent_modes_1 = {}\n",
    "\n",
    "for recording in recordings_1:\n",
    "    flist = os.listdir('%s/%s' % (DIR_READ_1, recording))\n",
    "    flist = [file for file in flist if not file.startswith('.')] # There are some hidden \n",
    "    # files on the hard drive starting with '.'; this step is necessary to ignore them\n",
    "    files = slow_text_finder(flist)\n",
    "    # print('Loading recording %s' % recording)\n",
    "    # print(files)\n",
    "    fnames = ['%s/%s/%s' % (DIR_READ_1, recording, filename) for filename in files]\n",
    "    vent_modes_1[recording] =  data_loader(fnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vent_modes_2 = {}\n",
    "\n",
    "for recording in recordings_2:\n",
    "    flist = os.listdir('%s/%s' % (DIR_READ_2, recording))\n",
    "    flist = [file for file in flist if not file.startswith('.')] # There are some hidden \n",
    "    # files on the hard drive starting with '.'; this step is necessary to ignore them\n",
    "    files = slow_text_finder(flist)\n",
    "    # print('Loading recording %s' % recording)\n",
    "    # print(files)\n",
    "    fnames = ['%s/%s/%s' % (DIR_READ_2, recording, filename) for filename in files]\n",
    "    vent_modes_2[recording] =  data_loader(fnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vent_modes = {**vent_modes_1, **vent_modes_2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vent_modes_selected = {} # only important mode parameters are kept in this one\n",
    "\n",
    "for recording in recordings:\n",
    "    vent_modes_selected[recording] = vent_mode_cleaner(vent_modes[recording])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import ventilator settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vent_settings_1 = {}\n",
    "\n",
    "for recording in recordings_1:\n",
    "    flist = os.listdir('%s/%s' % (DIR_READ_1, recording))\n",
    "    flist = [file for file in flist if not file.startswith('.')] # There are some hidden \n",
    "    # files on the hard drive starting with '.'; this step is necessary to ignore them\n",
    "    files = slow_setting_finder(flist)\n",
    "    # print('Loading recording %s' % recording)\n",
    "    # print(files)\n",
    "    fnames = ['%s/%s/%s' % (DIR_READ_1, recording, filename) for filename in files]\n",
    "    vent_settings_1[recording] =  data_loader(fnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vent_settings_2 = {}\n",
    "\n",
    "for recording in recordings_2:\n",
    "    flist = os.listdir('%s/%s' % (DIR_READ_2, recording))\n",
    "    flist = [file for file in flist if not file.startswith('.')] # There are some hidden \n",
    "    # files on the hard drive starting with '.'; this step is necessary to ignore them\n",
    "    files = slow_setting_finder(flist)\n",
    "    # print('Loading recording %s' % recording)\n",
    "    # print(files)\n",
    "    fnames = ['%s/%s/%s' % (DIR_READ_2, recording, filename) for filename in files]\n",
    "    vent_settings_2[recording] =  data_loader(fnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vent_settings = {**vent_settings_1, **vent_settings_2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vent_settings_selected = {} # only important mode parameters are kept in this one\n",
    "\n",
    "for recording in recordings:\n",
    "    vent_settings_selected[recording] = vent_settings_cleaner(vent_settings[recording])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify recordings that have HFOV periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify recordings which have HFOV mode and collect their name in a list\n",
    "# Print those ones which do not have PC_AC periods\n",
    "recordings_hfov = []\n",
    " \n",
    "for recording in recordings:\n",
    "    a = (vent_modes_selected[recording]['Text'])\n",
    "    if ' Mode PC-HFO' in a.values:\n",
    "        # 'recordings_hfov' is the list of recording names that contain \n",
    "        # HFOV ventilation periods\n",
    "        recordings_hfov.append(recording)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(recordings_hfov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(recordings_hfov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recordings_hfov_1 = [recording for recording in recordings_hfov if recording in recordings_1]\n",
    "recordings_hfov_2 = [recording for recording in recordings_hfov if recording in recordings_2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import ventilator parameters obtained with 1Hz sampling rate (\"slow measurements\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "slow_measurements_1 = {}\n",
    "\n",
    "for recording in recordings_hfov_1:\n",
    "    flist = os.listdir('%s/%s' % (DIR_READ_1, recording))\n",
    "    flist = [file for file in flist if not file.startswith('.')] # There are some hidden \n",
    "    # files on the hard drive starting with '.'; this step is necessary to ignore them\n",
    "    files = slow_measurement_finder(flist)\n",
    "    print('Loading recording %s' % recording)\n",
    "    print(files)\n",
    "    fnames = ['%s/%s/%s' % (DIR_READ_1, recording, filename) for filename in files]\n",
    "    slow_measurements_1[recording] =  data_loader(fnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slow_measurements_2 = {}\n",
    "\n",
    "for recording in recordings_hfov_2:\n",
    "    flist = os.listdir('%s/%s' % (DIR_READ_2, recording))\n",
    "    flist = [file for file in flist if not file.startswith('.')] # There are some hidden \n",
    "    # files on the hard drive starting with '.'; this step is necessary to ignore them\n",
    "    files = slow_measurement_finder(flist)\n",
    "    print('Loading recording %s' % recording)\n",
    "    print(files)\n",
    "    fnames = ['%s/%s/%s' % (DIR_READ_2, recording, filename) for filename in files]\n",
    "    slow_measurements_2[recording] =  data_loader(fnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slow_measurements = {**slow_measurements_1, **slow_measurements_2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resample to remove half-empty rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "for recording in recordings_hfov:\n",
    "    slow_measurements[recording] = slow_measurements[recording].resample('1S').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Remove non-HFOV periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Remove rows which have no DCO2 data - \n",
    "# this keeps HFOV periods only in 'slow_measurements_hfov'\n",
    "\n",
    "for recording in recordings_hfov:\n",
    "    print(recording)\n",
    "    print('before_removal: %d seconds' % len(slow_measurements[recording]))\n",
    "    # considers only 'DCO2' column when removing rows with NA values\n",
    "    slow_measurements[recording].dropna(subset = ['5001|DCO2 [10*mL^2/s]'], inplace = True)\n",
    "    print('after_removal:  %d seconds' % len(slow_measurements[recording]), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add current body weight to the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for recording in recordings_hfov:  \n",
    "        \n",
    "    slow_measurements[recording]['weight'] =  current_weights[recording]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correct DCO2 data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The original values need to be multiplied by 10 as in the the downloaded data \n",
    "# they are expressed as 1/10th of the DCO2 readings (see original column labels)\n",
    "\n",
    "for recording in recordings_hfov:\n",
    "\n",
    "    slow_measurements[recording]['5001|DCO2 [mL^2/s]'] = \\\n",
    "        slow_measurements[recording]['5001|DCO2 [10*mL^2/s]'] * 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correct the problem with Phf column names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The amplitude column is named differently in some recordings: *DG025* has only '5001|ΔPhf [mbar]' while *DG005_1*  and *DG069_2* has both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [recording for recording in recordings_hfov\n",
    "         if '5001|?Phf [mbar]' in slow_measurements[recording].columns]\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = [recording for recording in recordings_hfov \n",
    "     if '5001|ΔPhf [mbar]' in slow_measurements[recording].columns]\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Correct DG025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slow_measurements['DG025']['5001|?Phf [mbar]'] = \\\n",
    "            slow_measurements['DG025']['5001|ΔPhf [mbar]']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Correct DG005_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slow_measurements['DG005_1']['5001|ΔPhf [mbar]'].value_counts(dropna = False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(slow_measurements['DG005_1']['5001|ΔPhf [mbar]'].notnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slow_measurements['DG005_1']['5001|?Phf [mbar]'].value_counts(dropna = False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(slow_measurements['DG005_1']['5001|?Phf [mbar]'].notnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.concat([slow_measurements['DG005_1']['5001|?Phf [mbar]'].dropna(), \n",
    "                  slow_measurements['DG005_1']['5001|ΔPhf [mbar]'].dropna()])\n",
    "    \n",
    "slow_measurements['DG005_1']['5001|?Phf [mbar]'] = \\\n",
    "                temp.reindex_like(slow_measurements['DG005_1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(slow_measurements['DG005_1']['5001|?Phf [mbar]'].notnull())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Correct DG069_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slow_measurements['DG069_2']['5001|ΔPhf [mbar]'].value_counts(dropna = False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(slow_measurements['DG069_2']['5001|ΔPhf [mbar]'].notnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slow_measurements['DG069_2']['5001|?Phf [mbar]'].value_counts(dropna = False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(slow_measurements['DG069_2']['5001|?Phf [mbar]'].notnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.concat([slow_measurements['DG069_2']['5001|?Phf [mbar]'].dropna(), \n",
    "                  slow_measurements['DG069_2']['5001|ΔPhf [mbar]'].dropna()])\n",
    "    \n",
    "slow_measurements['DG069_2']['5001|?Phf [mbar]'] = \\\n",
    "                temp.reindex_like(slow_measurements['DG069_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(slow_measurements['DG069_2']['5001|?Phf [mbar]'].notnull())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rename columns and remove unimportant columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dictionary to rename \"clumsy\" column names with simple ones\n",
    "\n",
    "old = ['5001|% leak [%]', '5001|?Phf [mbar]', '5001|FiO2 [%]', '5001|FlowDev [L/min]', \n",
    "       '5001|MV [L/min]', '5001|MVe [L/min]', '5001|MVi [L/min]', '5001|MVleak [L/min]', \n",
    "       '5001|Pmean [mbar]', '5001|VThf [mL]', '5001|DCO2 [mL^2/s]']\n",
    "\n",
    "new = ['leak%', 'amplitude', 'fiO2', 'flow', 'MV', 'MVe', 'MVi', \n",
    "       'MVleak', 'MAP', 'VThf', 'DCO2']\n",
    "\n",
    "rename_dict = dict(zip(old, new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename column names and removing unimportant columns\n",
    "\n",
    "for recording in recordings_hfov:\n",
    "    slow_measurements[recording].rename(columns=rename_dict, inplace=True)\n",
    "    to_delete = [par for par in list(slow_measurements[recording]) \n",
    "                if par.startswith('5001') or par.startswith('8272')]\n",
    "    slow_measurements[recording] = slow_measurements[recording].drop(to_delete, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve the set frequency (Hz) and adding it to the DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = {}\n",
    "for recording in recordings_hfov:\n",
    "    freq[recording] = vent_settings[recording][vent_settings[recording].Id == 'fhf'].copy()\n",
    "    freq[recording]['frequency'] = freq[recording]['Value New']\n",
    "    # reindex the freq Dataframe with the index of slow_measurements will allow concatenation\n",
    "    # with the freq data filled in for all rows of the slow_measurements DataFrame\n",
    "    freq[recording] = freq[recording].reindex(slow_measurements[recording].index, method = 'ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for recording in recordings_hfov:\n",
    "    slow_measurements[recording] = pd.concat([slow_measurements[recording], freq[recording]],\n",
    "                                            join = 'inner', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for recording in recordings_hfov:\n",
    "    slow_measurements[recording].drop(['Time [ms]', 'Rel.Time [s]', 'Value Old',\n",
    "                                       'Value New', 'Date_Time', 'Date', 'Time',\n",
    "                                       'Id', 'Name', 'Unit'], axis=1, inplace=True )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final lengths of the preprocessed recordings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('Length of the recordings in seconds: \\n')\n",
    "for recording in recordings_hfov:\n",
    "    print('%-10s %-10.d' % (recording, len(slow_measurements[recording])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_periods = {}\n",
    "for recording in recordings_hfov:\n",
    "    start = str(slow_measurements[recording].index[0])\n",
    "    end = str(slow_measurements[recording].index[-1])\n",
    "    recording_periods[recording] = [start, end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_duration_frame = DataFrame(recording_periods, index = ['start', 'end'])\n",
    "recording_duration_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add the recording's name to the DataFrames as a categorical variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for recording in recordings_hfov:\n",
    "    slow_measurements[recording]['recording'] = recording "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limit ventilation settings to HFOV recordings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit to recordings containing HFOV\n",
    "\n",
    "vent_settings_selected = {key : value  for key, value in vent_settings_selected.items() if\n",
    "                          key in recordings_hfov}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vent_settings_selected['DG089'].sort_index(inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limit clinical details to the hfov recordings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clinical_details_hfov = clinical_details.loc[recordings_hfov]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export data to pickle files¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec1 = recordings_hfov[:int(len(recordings_hfov) * 0.5)] \n",
    "rec2 = recordings_hfov[int(len(recordings_hfov) * 0.5):] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slow_measurements_1 = { key: value for key, value in slow_measurements.items() if key in rec1}\n",
    "with open('%s/%s.pickle' % (DATA_DUMP, 'slow_measurements_hfov_1'), 'wb') as handle:\n",
    "    pickle.dump(slow_measurements_1, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slow_measurements_2 = { key: value for key, value in slow_measurements.items() if key in rec2}\n",
    "with open('%s/%s.pickle' % (DATA_DUMP, 'slow_measurements_hfov_2'), 'wb') as handle:\n",
    "    pickle.dump(slow_measurements_2, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('%s/%s.pickle' % (DATA_DUMP, 'vent_settings_selected_hfov'), 'wb') as handle:\n",
    "    pickle.dump(vent_settings_selected, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('%s/%s.pickle' % (DATA_DUMP, 'clinical_details_hfov'), 'wb') as handle:\n",
    "    pickle.dump(clinical_details_hfov, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Export data as Excel files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter('%s/%s' % (DIR_WRITE, 'ventilator_modes.xlsx'))\n",
    "for recording in recordings_hfov:\n",
    "    vent_modes[recording].to_excel(writer,'%s' % recording)\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter('%s/%s' % (DIR_WRITE, 'ventilator_modes_selected.xlsx'))\n",
    "for recording in recordings_hfov:\n",
    "    vent_modes_selected[recording].to_excel(writer,'%s' % recording)\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter('%s/%s' % (DIR_WRITE, 'ventilator_settings.xlsx'))\n",
    "for recording in recordings_hfov:\n",
    "    vent_settings[recording].to_excel(writer,'%s' % recording)\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter('%s/%s' % (DIR_WRITE, 'ventilator_settings_selected.xlsx'))\n",
    "for recording in recordings_hfov:\n",
    "    vent_settings_selected[recording].to_excel(writer,'%s' % recording)\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter('%s/%s' % (DIR_WRITE, 'clinical_details.xlsx'))\n",
    "clinical_details_hfov.to_excel(writer,'clinical_details')\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter('%s/%s' % (DIR_WRITE, 'recording_periods.xlsx'))\n",
    "recording_duration_frame.T.to_excel(writer,'rec_periods.xlsx')\n",
    "writer.save()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
